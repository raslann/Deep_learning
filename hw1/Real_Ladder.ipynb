{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle \n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n",
      "3000\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "trainset_labeled = pickle.load(open(\"train_labeled.p\", \"rb\")) \n",
    "train_loader  = torch.utils.data.DataLoader(trainset_labeled, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "validset = pickle.load(open(\"validation.p\", \"rb\"))\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_numpy = trainset_labeled.train_data.numpy()\n",
    "#train_numpy = np.concatenate((train_numpy, train_numpy),0)\n",
    "train_labels_numpy = trainset_labeled.train_labels.numpy()\n",
    "#train_labels_numpy = np.concatenate((train_labels_numpy, train_labels_numpy),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vshift' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bc404d2b3a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vshift' is not defined"
     ]
    }
   ],
   "source": [
    "np.zeros((3000,np.max(0,vshift),28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_shifted = copy.copy(train_numpy)\n",
    "train_labeled_shifted = copy.copy(train_labels_numpy)\n",
    "train_numpy.shape\n",
    "for hshift in range(-4,6,2):\n",
    "    for vshift in range(-4,6,2):\n",
    "        next_shift = np.concatenate((np.zeros((3000,np.max((0,vshift)),28)),\n",
    "                                      train_numpy[:,np.max((0,vshift)):np.min((28,28+vshift)),:],\n",
    "                                      np.zeros((3000,np.max((0,-1*vshift)),28))),1)\n",
    "        \n",
    "        next_shift = np.concatenate((np.zeros((3000,28,np.max((0,hshift)))),\n",
    "                                      next_shift[:,:,np.max((0,hshift)):np.min((28,28+hshift))],\n",
    "                                      np.zeros((3000,28,np.max((0,-1*hshift))))),2)\n",
    "        \n",
    "        train_shifted = np.concatenate((train_shifted, next_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_shifted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.ones(3)\n",
    "a[-1:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset_labeled.train_data = torch.ByteTensor(train_numpy)\n",
    "trainset_labeled.train_labels = torch.LongTensor(train_labels_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._C.sigmoid>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(trainset_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def rand(x, level = 1e-3):\n",
    "    return x + torch.randn(x.size()) * level\n",
    "\n",
    "def norm_weights_2d(size):\n",
    "    return BatchNorm2d(nn.Linear(size))\n",
    "def norm_weights_1d(size):\n",
    "    return BatchNorm2d(nn.Linear(size))\n",
    "\n",
    "def reluN(x, level = 1e-3):\n",
    "    y = x + torch.randn(x.size()) * level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-1564595a6124>, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-1564595a6124>\"\u001b[0;36m, line \u001b[0;32m42\u001b[0m\n\u001b[0;31m    self.u =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def norm(size, dim = 1):\n",
    "    if dim == 1:\n",
    "        return torch.nn.BatchNorm1d(size)\n",
    "    else:\n",
    "        return torch.nn.BatchNorm2d(size)\n",
    "    \n",
    "\n",
    "def linear(indim, outdim):\n",
    "    return nn.Linear(indim, outdim)\n",
    "def var(tens):\n",
    "    # The whole torch.nn module uses Parameter objects, which are essentially wrappers\n",
    "    # of autograd Variables.\n",
    "    return torch.nn.Parameter(tens)\n",
    "def randn(size):\n",
    "    return torch.randn(size)\n",
    "def matmul(w1, w2):\n",
    "    return w1.mm(w2)\n",
    "\n",
    "def broad(tens, bs):\n",
    "    size = list(tens.size())\n",
    "    return tens.unsqueeze(0).expand(*([bs] + l))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def u(self, v, z):\n",
    "        \n",
    "        return self.normalize_vector(v(z))\n",
    "    \n",
    "    def normalize_vector(self, vect):\n",
    "        vectmean = vect.mean()\n",
    "        vectstd = vect.std()\n",
    "        vznorm = (vect - vectmean) / vectstd\n",
    "        return vznorm\n",
    "    \n",
    "    def normalize_vector_noise(self, vect, noise):\n",
    "        vectmean = vect.mean()\n",
    "        vectstd = vect.std()\n",
    "        vznorm = (vect - vectmean) / vectstd\n",
    "        return vznorm + noise\n",
    "    \n",
    "    \n",
    "        \n",
    "    def mu_v(u, a1, a2, a3, a4, a5):\n",
    "        bs = u.size()[0]\n",
    "        a_size = a1.size()[0]\n",
    "        return (a1.unsqueeze(0).expand(bs,a_size) * \n",
    "            torch.sigmoid(a2.unsqueeze(0).expand(bs,a_size) * u + a3.unsqueeze(0).expand(bs,a_size)) + \n",
    "            a4.unsqueeze(0).expand(bs,a_size) * u + a5.unsqueeze(0).expand(bs,a_size))\n",
    "        \n",
    "    #z is lateral, u is vetrtical from above\n",
    "    def g(self, z, u, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10):\n",
    "        return (z - mu_v(u, a1, a2, a3, a4, a5)) * mu_v(u, a6, a7, a8, a9, a10) + mu_v(u, a1, a2, a3, a4, a5)\n",
    "        \n",
    "        \n",
    "    def __init__(self, layers = [100, 100, 100]):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = layers\n",
    "        layers = self.layers\n",
    "        self.encs = [linear(28*28, layers[0])]\n",
    "        self.u = \n",
    "        self.lats = []\n",
    "        self.encnorms = []\n",
    "        self.purenorms = []\n",
    "        self.decs = []\n",
    "        self.decnorms = []\n",
    "        self.a1s = []\n",
    "        self.a2s = []\n",
    "        self.a3s = []\n",
    "        self.a4s = []\n",
    "        self.a5s = []\n",
    "        self.a6s = []\n",
    "        self.a7s = []\n",
    "        self.a8s = []\n",
    "        self.a9s = []\n",
    "        self.a10s = []\n",
    "        \n",
    "        def _add_module_to_list(name, module, module_list):\n",
    "            self.__setattr__(name, module)\n",
    "            module_list.append(module)\n",
    "\n",
    "        for idx, l in enumerate(layers):\n",
    "            # When setting any attribute in a Module, PyTorch will try to figure out\n",
    "            # what kind of value it is: if it is a Parameter or a Module, PyTorch\n",
    "            # will automatically add the Parameter or Module into the parameter/module\n",
    "            # list.  I'm not sure if this is a good pattern in Python because adding\n",
    "            # modules invisibly like this would cause problems if one wants to maintain\n",
    "            # modules in list attributes for dynamicity (like here).  I would rather\n",
    "            # require the developers to always explicitly add modules with \"add_module()\"\n",
    "            # (I'm more convinced to avoid deriving from Module in general).\n",
    "            _add_module_to_list('_encnorm%d' % idx, norm(l), self.encnorms)\n",
    "            _add_module_to_list('_purenorm%d' % idx, norm(l), self.purenorms)\n",
    "            if idx < len(layers) - 1:\n",
    "                _add_module_to_list('_lat%d' % idx, linear(l, l), self.lats)\n",
    "                _add_module_to_list('_enc%d' % idx, linear(l, layers[idx+1]), self.encs)\n",
    "                _add_module_to_list('_dec%d' % idx, linear(layers[idx+1], l), self.decs)\n",
    "                _add_module_to_list('_decnorm%d' % idx, norm(l), self.decnorms)\n",
    "                \n",
    "                _add_module_to_list('_a1s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a1s)\n",
    "                _add_module_to_list('_a2s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a2s)\n",
    "                _add_module_to_list('_a3s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a3s)\n",
    "                _add_module_to_list('_a4s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a4s)\n",
    "                _add_module_to_list('_a5s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a5s)\n",
    "                _add_module_to_list('_a6s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a6s)\n",
    "                _add_module_to_list('_a7s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a7s)\n",
    "                _add_module_to_list('_a8s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a8s)\n",
    "                _add_module_to_list('_a9s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a9s)\n",
    "                _add_module_to_list('_a10s%d' % idx, nn.parameter(torch.randn(l)*1e-3), self.a10s)\n",
    "        self.batch_size = 64\n",
    "        self.weights = [self.encs, self.lats, self.decs]\n",
    "        \n",
    "\n",
    "    def forward(self, x, v = 0, noise=1e-3):\n",
    "        self.eps = noise\n",
    "        self.batch_size = x.size()[0]\n",
    "        bs = self.batch_size\n",
    "        #enc= F.relu(self.enc4(F.relu(self.enc3(F.relu(self.enc2(F.relu(self.enc1(x))))))))\n",
    "        corrupted = []\n",
    "        corruptedout = []\n",
    "        corrupted_pre_scaled = []\n",
    "        for idx, l in enumerate(self.layers):\n",
    "            if idx == 0:\n",
    "                corrupted.append(self.encnorms[idx](self.encs[idx](x)))\n",
    "                cur_noise = var(randn(corrupted[-1].size()) * self.eps)\n",
    "                corrupted_pre_scaled.append(self.normalize_vector_noise(self.encs[idx](x), cur_noise))\n",
    "            else:\n",
    "                corrupted.append(self.encnorms[idx](self.encs[idx](corruptedout[-1])))\n",
    "                cur_noise = var(randn(corrupted[-1].size()) * self.eps)\n",
    "                corrupted_pre_scaled.append(self.normalize_vector_noise(self.encs[idx](corruptedout[-1]), cur_noise))\n",
    "                \n",
    "            corruptedout.append(F.relu(corrupted[-1] + self.encnorms[idx].weight.unsqueeze(0).expand(\n",
    "                    bs, l) * cur_noise +\n",
    "                    self.encnorms[idx].bias.unsqueeze(0).expand(bs, l)))\n",
    "            \n",
    "        encout = F.softmax(corruptedout[-1])\n",
    "        \n",
    "        clean = [x]\n",
    "        clean_pre_scaled = []\n",
    "        mu_l = []\n",
    "        std_l = []\n",
    "        for norm, enc in zip(self.encnorms, self.encs):\n",
    "            clean_pre_scaled.append(self.normalize_vector(clean[-1]))\n",
    "            mu_l.append(clean_pre_scaled[-1].mean())\n",
    "            std_l.append(clean_pre_scaled[-1].std())\n",
    "            clean.append(F.relu(norm(enc(clean[-1]))))\n",
    "        \n",
    "        #Decout starts as the output. For future iterations down decoding path,\n",
    "        #Decout[-1] will contain V*Z of above decoder\n",
    "        decout = [encout]\n",
    "        z_hats = []\n",
    "        for idx in range(len(self.layers) - 2, -1, -1):\n",
    "            a1, a2, a3, a4, a5 a6, a7, a8, a9, a10 = a1s[idx], a1s[idx], a2s[idx], a3s[idx], \\\n",
    "                a4s[idx], a5s[idx], a6s[idx], a7s[idx], a8s[idx], a9s[idx], a10s[idx]\n",
    "            \n",
    "            decin = decout[-1]\n",
    "            U_l = self.normalize_vector(decin)\n",
    "            z_tild = corrupted_pre_scaled[idx]\n",
    "            z_hat = self.g(z_tild, U_l)\n",
    "            z_hats.append(z_hat - mu[idx])\n",
    "            \n",
    "            \n",
    "            \n",
    "            v = decs[idx]\n",
    "                \n",
    "            dec = self.decs[idx]\n",
    "            lat = self.lats[idx]\n",
    "            decnorm = self.decnorms[idx]\n",
    "            decin.append(dec(decout[-1]) + lat(corruptedout[idx]))\n",
    "            decout.append(F.relu(decin[-1] + decnorm.weight.unsqueeze(0).expand(bs, self.layers[idx]) *\n",
    "                    var(randn(decin[-1].size()) * self.eps) + \\\n",
    "                    decnorm.bias.unsqueeze(0).expand(bs, self.layers[idx])))\n",
    "        weight_reg = 0\n",
    "        for w_list in self.weights:\n",
    "            for w in w_list:\n",
    "                weight_reg += (w.weight**2).mean()/100\n",
    "        \n",
    "        yhat = F.log_softmax(corruptedout[-1])\n",
    "        \n",
    "        encode_err = 0\n",
    "        enc_weight = 1\n",
    "        enc_decay = .5\n",
    "        for c, d in zip(clean[-2::-1], decin):\n",
    "            encode_err += enc_weight * ((c - d)**2).mean()\n",
    "            enc_weight *= enc_decay\n",
    "        return yhat, weight_reg + encode_err\n",
    "        \n",
    "\n",
    "model = Net([600, 300, 200, 100])\n",
    "params = list(model.parameters())\n",
    "\n",
    "if 0:\n",
    "    print(model)\n",
    "    print('Models has {} learnable paramater:'.format(len(params)))\n",
    "    [print('parameter {} has a size of {}'.format(i+1, params[i].size())) for i in range(len(params))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target) # Wrap them in Variable \n",
    "        optimizer.zero_grad() # Zero the parameter gradients\n",
    "        data = data.view(data.size()[0], 28*28)\n",
    "        outputs = model(data,noise=1e-2) # Forward \n",
    "        output = outputs[0]\n",
    "        US = outputs[1]\n",
    "        loss = F.nll_loss(output, target) + US*.1\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of non-empty torch.ByteTensor objects is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    381\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_default_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_safe_getattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_baseclass_reprs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# A user-provided repr. Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_line\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36marray_repr\u001b[0;34m(arr, max_line_width, precision, suppress_small)\u001b[0m\n\u001b[1;32m   1805\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0;32m-> 1807\u001b[0;31m                            ', ', \"array(\")\n\u001b[0m\u001b[1;32m   1808\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[], shape=%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         lst = _array2string(a, max_line_width, precision, suppress_small,\n\u001b[0;32m--> 447\u001b[0;31m                             separator, prefix, formatter=formatter)\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, formatter)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     formatdict = {'bool': _boolFormatter,\n\u001b[0;32m--> 260\u001b[0;31m                   \u001b[0;34m'int'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIntegerFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                   \u001b[0;34m'float'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloatFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                   \u001b[0;34m'longfloat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLongFloatFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             max_str_len = max(len(str(maximum.reduce(data))),\n\u001b[0m\u001b[1;32m    638\u001b[0m                               len(str(minimum.reduce(data))))\n\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_str_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         raise RuntimeError(\"bool value of non-empty \" + torch.typename(self) +\n\u001b[0;32m--> 148\u001b[0;31m                            \" objects is ambiguous\")\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of non-empty torch.ByteTensor objects is ambiguous"
     ]
    }
   ],
   "source": [
    "np.array(trainset_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target) # Wrap them in Variable\n",
    "        optimizer.zero_grad() # Zero the parameter gradients\n",
    "        data = data.view(data.size()[0], 28*28)\n",
    "        data2 = data.clone()\n",
    "        '''\n",
    "        for flips in range(3):\n",
    "            if flips == 0:\n",
    "                hshift = np.random.randint(10)\n",
    "                vshift = np.random.randint(10)\n",
    "                data2 = copy.deepcopy(data.resize_as(torch.FloatTensor(data.size()[0], 28, 28)))\n",
    "                #data2 = data.resize_as(torch.FloatTensor(data.size()[0], 28, 28))\n",
    "                if 1:\n",
    "                    data2[:,:,hshift:] = data2[:,:,:28-hshift]\n",
    "                    data2[:,:,:hshift] = 0\n",
    "                    #data2 = torch.cat((torch.FloatTensor(data.size()[0], 28,hshift), data2[:,:,hshift:]))\n",
    "            if flips == 1:\n",
    "                data2 = data.resize_as(torch.FloatTensor(data.size()[0], 28, 28))\n",
    "                data2 = data2.transpose(1,2)\n",
    "                data2 = data2.resize_as(torch.FloatTensor(data.size()[0], 784))\n",
    "            if flips == 2:\n",
    "                data2 = data\n",
    "        '''\n",
    "        outputs = model(data,noise=1e-2) # Forward \n",
    "        output = outputs[0]\n",
    "        US = outputs[1]\n",
    "        loss = F.nll_loss(output, target) + US*.1\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5188185825348912\n"
     ]
    }
   ],
   "source": [
    "lshift = np.random.random()\n",
    "print(lshift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(epoch, valid_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in valid_loader:\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            data = data.view(data.size()[0], 28*28)\n",
    "            outputs = model(data, noise = 0)\n",
    "            output = outputs[0]\n",
    "            test_loss += F.nll_loss(output, target).data[0]\n",
    "            pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "    test_loss /= len(valid_loader) # loss function already averages over batch size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(valid_loader.dataset),\n",
    "        100. * correct / len(valid_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3000 (0%)]\tLoss: 4.682650\n",
      "Train Epoch: 1 [640/3000 (21%)]\tLoss: 3.249107\n",
      "Train Epoch: 1 [1280/3000 (43%)]\tLoss: 2.794274\n",
      "Train Epoch: 1 [1920/3000 (64%)]\tLoss: 2.401498\n",
      "Train Epoch: 1 [2560/3000 (85%)]\tLoss: 2.018213\n",
      "\n",
      "Test set: Average loss: 1.7966, Accuracy: 9049/10000 (90%)\n",
      "\n",
      "Train Epoch: 2 [0/3000 (0%)]\tLoss: 1.722873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-5:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c8a36916e533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6466ce135b58>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mUS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lee/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-6:\n",
      "  File \"/home/lee/anaconda3/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lee/anaconda3/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 30):\n",
    "    train(epoch)\n",
    "    test(epoch, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-67b2031bb4e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomHorizontalFlip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.RandomHorizontalFlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of size 3]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "asNumpyarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-07016687bdda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masNumpyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: asNumpyarray"
     ]
    }
   ],
   "source": [
    "a.asNumpyarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "          ...             â‹±             ...          \n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "[torch.FloatTensor of size 64x784]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(range(784,-1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "-0.4242\n",
       "[torch.FloatTensor of size 64]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataarr[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-5350a1bf76ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'image'"
     ]
    }
   ],
   "source": [
    "torch.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "scale",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-f2af4eacecd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lee/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: scale"
     ]
    }
   ],
   "source": [
    "dataarr.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torchvision.transforms' from '/home/lee/anaconda3/lib/python3.5/site-packages/torchvision-0.1.6-py3.5.egg/torchvision/transforms.py'>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
